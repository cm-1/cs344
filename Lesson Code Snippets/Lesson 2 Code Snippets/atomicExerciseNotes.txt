Originally, when trying the 1M-element array version on Windows, the program
would compile without error/warning, and would run without printing any
exceptions, but the program wouldn't print/do anything. When I tried to debug,
it didn't even make it to the first line. It turned out that the reason was
Windows has a max stack size of 1MB, which the h_array was exceeding.
So, I had to declare h_array on the heap instead and then manually delete it at
the end of the program. Anyway, onto the results.

Below, I'll use the shorthand "T" for threads and "E" for elements.
Also, "A" for atomic and "N" for naive.

A 1,000,000 T --- 10,000 E:       ~0.125 ms (the original, unedited code)
A 1,000,000 T --- 1,000,000 E:    ~0.024 ms
N 1,000,000 T --- 1,000,000 E:    ~0.035 ms
A 1,000,000 T --- 100 E:          ~0.125 ms
N 1,000,000 T --- 100 E:          ~0.0225 ms
A 10,000,000 T --- 100 E:         ~1.22 ms

The video explains these differences as arising from a few things.
First, writing naively to 100 elements is a bit faster than 1,000,000 because of caching.
Interestingly, writing atomically to 1M elements is faster than naively on my device.
I don't know why this is, and the video's several years old at this point, so
maybe there's been some relatively-recent development that causes this.
Of course, the version with 10M threads is slowest because it's doing the most stuff.


